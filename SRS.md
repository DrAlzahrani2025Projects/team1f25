# Software Requirements Specification (SRS)

Project: Scholar AI Assistant
Repository: team1f25
Author: Automated spec (draft)
Last Updated: 2025-11-02

## 1. Purpose
This SRS describes the functional and non-functional requirements for the Scholar AI Assistant — a conversational Streamlit application that helps users discover academic resources from the CSUSB library by understanding their research needs and returning curated search results.

Intended readers: developers, testers, maintainers, DevOps, and stakeholders at CSUSB.

## 2. Scope
The system provides a chat-based interface that accepts natural language user input, uses an LLM (Groq) to analyze intent and extract search parameters, queries the CSUSB Primo API, formats results, and presents them in a table with links. The system also offers suggestions when no results are found and supports a simple session state and UI controls.

Out-of-scope: full user account management, persistence beyond a session, multi-user concurrency control beyond Streamlit's defaults, and advanced access control.

## 3. Definitions, Acronyms, and Abbreviations
- LLM: Large Language Model
- Groq: the LLM provider used (`groq` Python client)
- Primo: CSUSB library discovery API (Primo/PrimoWS)
- UI: User Interface (Streamlit)
- API key: GROQ_API_KEY environment variable

## 4. System Overview
Components (high-level):
- Streamlit front-end (`app.py`, `ui/`): chat UI, sidebar, results rendering
- Chat orchestrator (`ui/chat_handler.py`): orchestrates conversation and search
- Conversation analyzer (`core/services/conversation_analyzer.py`): uses LLM to decide readiness & extract parameters
- Suggestion service (`core/services/suggestion_service.py`): generates alternative queries
- Search service (`core/services/search_service.py`): interfaces with library client and formats results
- Clients (`core/clients/`): `GroqClient` (LLM), `CSUSBLibraryClient` (Primo)
- Formatter (`core/services/result_formatter.py`): parse and prepare table data
- Utilities: logging, prompts, error handlers
- Tests: comprehensive unit/integration/e2e test suites under `tests/`

Deployment: Containerized (Docker); includes scripts in `scripts/` and `docker/` for building and running.

## 5. Stakeholders and Users
- Students and researchers at CSUSB (end users)
- Library staff and administrators
- Developers and maintainers of the project
- Course instructors using the project for teaching

## 6. Functional Requirements
Each requirement is assigned an identifier (FR-#).

FR-1: Conversational Input
- The system shall accept natural language input via a chat box (`st.chat_input`).
- Priority: High
- Acceptance: User can type a query and receive a chatbot response.

FR-2: Determine Search Intent
- The system shall detect explicit user requests to search (e.g., "search now", "find articles") using `ConversationAnalyzer.should_trigger_search`.
- Priority: High
- Acceptance: Queries containing trigger keywords initiate a search.

FR-3: LLM Follow-up & Readiness
- The system shall call the LLM to generate follow-up questions and detect readiness markers (e.g., `READY_TO_SEARCH`) via `ConversationAnalyzer.get_follow_up_response`.
- Priority: High
- Acceptance: The orchestrator triggers search when the LLM returns READY_TO_SEARCH.

FR-4: Parameter Extraction
- The system shall extract search parameters (query text, result limit, resource type) from conversation history using the LLM and parse JSON responses.
- Priority: High
- Acceptance: `extract_search_parameters` returns a dict with `query`, `limit`, and optional `resource_type`.

FR-5: Library Search
- The system shall query the CSUSB Primo public API via `CSUSBLibraryClient` and `SearchService.perform_library_search` with `query`, `limit`, `offset`, and `resource_type`.
- Priority: High
- Acceptance: Service returns a dict with `docs` list and `info.total`.

FR-6: Result Formatting
- The system shall format results into a table-friendly structure using `ResultFormatter.format_table_data` and present a Streamlit `st.dataframe` with columns: #, Title, Authors, Year, Type, Link.
- Priority: High
- Acceptance: Results table displayed with clickable link icons that open the Primo fulldisplay.

FR-7: Display Searched Keyword
- The UI shall show the last searched keyword above the result table (session state `last_search_query`).
- Priority: Medium
- Acceptance: When search results are present, the UI displays the keyword.

FR-8: No-results Suggestions
- When no results are returned, the system shall present alternative suggestions generated by the SuggestionService.
- Priority: Medium
- Acceptance: The user sees a list of suggested alternative searches.

FR-9: Start New Search
- The system shall provide a control in the sidebar to start a new search (clearing session state and messages).
- Priority: Medium
- Acceptance: Clicking the button resets session state and shows initial greeting.

FR-10: Error Handling
- The system shall gracefully handle errors from LLM and library APIs, display user-friendly messages, and log details internally.
- Priority: High
- Acceptance: On failures, the user receives an informative message and logs capture the error.

FR-11: Logging & Debugging
- The system shall produce configurable logs using `core.utils.logging_utils.get_logger()` and respect `LOG_LEVEL` environment variable. Debug logs must be available for development.
- Priority: Medium
- Acceptance: Setting `LOG_LEVEL=DEBUG` increases verbosity.

FR-12: Testing
- The codebase shall include unit, integration, and e2e tests. Unit tests should not require network access. Integration tests must be guarded by API key availability.
- Priority: High
- Acceptance: `pytest` runs the test suite; markers separate categories.

## 7. Non-functional Requirements
NFR-1: Performance
- Search response (library API call + formatting) should complete within a reasonable user-perceived time (target: < 5 seconds for typical queries) depending on network/LLM latency.

NFR-2: Availability
- The app should be deployable as a container; uptime depends on hosting environment.

NFR-3: Scalability
- The Streamlit app is single-process by default; scale via container orchestration and load balancing if needed.

NFR-4: Security
- GROQ_API_KEY and any secrets must be provided via environment variables or secret management.
- Do not log full API keys. Avoid including PII in logs. Protect Primo responses if containing restricted data.

NFR-5: Maintainability
- Code follows SRP and DI patterns. New clients or formatters can be added with minimal changes.

NFR-6: Observability
- Logging must be structured and configurable. Debug logs added to key modules for tracing.

NFR-7: Portability
- App runs on Linux/macOS/Windows (with WSL for Docker on Windows). Docker support provided.

NFR-8: Internationalization
- Texts are English-only by default; future support can be added.

## 8. External Interfaces
- Groq LLM API via `groq` Python client (requires `GROQ_API_KEY` and model config such as `GROQ_MODEL`).
- CSUSB Primo public API (configurable base URL with `PRIMO_PUBLIC_BASE`).
- Streamlit UI served on host and port provided by the environment.

Environment variables (non-exhaustive):
- GROQ_API_KEY (required for Groq)
- GROQ_MODEL (optional)
- PRIMO_PUBLIC_BASE (optional override)
- LOG_LEVEL (INFO/DEBUG/etc.)
- PRIMO_* other overrides like VID, TAB, SCOPE, TIMEOUT

## 9. Data Requirements and Models
Search results are expected as a dict with keys:
- docs: list of document objects (Primo PNX data)
- info: object with `total` (int)

ResultFormatter expects within each doc:
- doc['pnx']['display'] with fields like `title`, `creator`, `type`, `creationdate`
- doc['pnx']['addata'] with `pub`, `issn`, `doi`, `date`
- doc['control'] with `recordid`

Table rows produced (example shape):
- #: int
- Title: str (truncated to ~80 chars)
- Authors: str (truncated to ~40 chars)
- Year: str
- Type: str
- Link: URL (string) or None

## 10. UI Requirements
- Use Streamlit chat UI for interactive conversation.
- Sidebar with About, Tips, and a Start New Search button.
- Main area with chat messages and a search results section.
- Results table must display the last search keyword above it and provide clickable link icons that open full record in a new tab.

## 11. Constraints and Assumptions
- The environment will provide a valid `GROQ_API_KEY` for LLM features.
- Network access to Primo API is available for integration tests and runtime.
- Streamlit environment is acceptable for the target user base.
- LLM output for parameter extraction is valid JSON; fallback extraction logic exists.

## 12. Error Handling and Recovery
- On LLM errors, the app returns a helpful fallback message and logs the exception.
- On library API failures (HTTP >= 400), the app logs and surfaces a user-friendly error.
- If parameter extraction fails, the system falls back to the last user message as the query.

## 13. Acceptance Criteria & Test Cases (Representative)
AC-1: Basic search flow
- Given a user enters a research topic, when the app detects search intent or LLM signals readiness, then it should perform a search and render results in the table.
- Tests: `tests/test_search.py`, `tests/unit/test_result_formatter.py`.

AC-2: No-results suggestion
- Given search returns zero docs, then the app should display suggestion text generated by the SuggestionService.
- Tests: `tests/test_no_results.py`.

AC-3: Parameter extraction
- Given a multi-turn conversation, when extractor runs, then it returns JSON containing `query`, `limit` and optional `resource_type`.
- Tests: `tests/unit/test_conversation_analyzer.py`.

AC-4: Logging
- Given LOG_LEVEL=DEBUG, debug messages from core modules should appear in logs.
- Tests: Observational/manual check; unit tests can assert that `get_logger` returns a logger and that functions run without raising.

## 14. Traceability Matrix
Map a few FRs to test files and components:
- FR-1 -> `ui/chat_handler.py`, `app.py` -> tests/test_user_query.py
- FR-4 -> `core/services/conversation_analyzer.py` -> tests/unit/test_conversation_analyzer.py
- FR-5 -> `core/clients/csusb_library_client.py`, `core/services/search_service.py` -> tests/integration/test_library_client.py
- FR-6 -> `core/services/result_formatter.py` -> tests/unit/test_result_formatter.py
- FR-8 -> `core/services/suggestion_service.py` -> tests/test_suggestions.py

## 15. Future Enhancements
- Persistent user preferences and saved searches.
- User authentication and per-user rate limiting.
- Caching of recent searches to reduce Primo API calls.
- Multi-language support and UI localization.
- Replace or parallelize Streamlit with a web frontend for heavy usage scenarios.
- Better LLM response verification and schema enforcement (e.g., JSON schema validation).

## 16. Appendix
### A: Key Files
- `app.py` — main Streamlit app entry
- `ui/` — UI components and session state
- `core/clients/` — Groq and Primo clients
- `core/services/` — analysis, search, formatting, suggestions
- `scripts/`, `docker/` — deployment helpers
- `tests/` — test suite

### B: Glossary
- See section 3 for abbreviations.

---

This SRS is a living document. If you'd like, I can:
- Expand sections into a longer document (detailed use cases, sequence diagrams)
- Generate a printable PDF
- Add a short set of acceptance test scripts or Gherkin scenarios

File created: `SRS.md` in the repository root.
